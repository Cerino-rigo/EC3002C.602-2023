{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cerino-rigo/EC3002C.602-2023/blob/main/RegresionLinealMultiple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2SmePwcn289"
      },
      "source": [
        " # **Modelos supervisados: Regresi贸n Lineal Multiple con `sklearn`**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tTVRht_XPly1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT2-msbVrSQk"
      },
      "source": [
        "## **Bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRdT1kd7rJ8o"
      },
      "source": [
        "# Operaciones matem谩ticas y estad铆sticas\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuHEoL90rnf2"
      },
      "source": [
        "# Visualizaci贸n\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj64cpBhsW4Q"
      },
      "source": [
        "## **Conjunto de Datos**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"/content/drive/MyDrive/Machine Learning/Ecommerce_Customers.csv\""
      ],
      "metadata": {
        "id": "tIUUi5_ULJFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arsPyTGL1Ydp"
      },
      "source": [
        "datos = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OorC6dqD1apN"
      },
      "source": [
        "datos.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Es una empresa de comercio electr贸nico con sede en la ciudad de Nueva York que vende ropa en l铆nea, pero tambi茅n tienen sesiones de asesoramiento sobre estilo y ropa en la tienda. Los clientes , tienen sesiones/reuniones con un estilista personal, luego pueden ordenar a trav茅s de una aplicaci贸n m贸vil o sitio web la ropa que desean.\n",
        "<br>\n",
        "<br>\n",
        "Intentan identificar si debe enfocarse en mejorar su experiencia de aplicaci贸n movil o en su p谩gina web.\n",
        "<br>\n",
        "<br>\n",
        "Este es un conjunto de datos de los clientes de la empresa. El cual tiene informaci贸n del cliente, como correo electr贸nico, direcci贸n postal y su color de avatar. Tambi茅n tiene columnas de valores num茅ricos:\n",
        "\n",
        "* **Avg. Session Length**: duraci贸n promedio de sesiones de asesoramiento de estilo en la tienda.\n",
        "\n",
        "* **Time on App**: tiempo promedio de permanencia en la aplicaci贸n en minutos.\n",
        "\n",
        "* **Time on Website**: tiempo promedio de permanencia en el sitio web en minutos.\n",
        "\n",
        "* **Length of Membership**: cu谩ntos a帽os ha sido miembro el cliente.\n",
        "\n",
        "* **Yearly Amount Spent**: monto anual gastado en la plataforma.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_uKB9hczk38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "0RsmeDhgmnrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "En la biblioteca <code>Pandas</code>, el m茅todo <code>unique()</code> se utiliza para obtener los valores 煤nicos presentes en una serie o columna de un DataFrame. El objetivo es revisar que no hayan clientes repetidos.  "
      ],
      "metadata": {
        "id": "lh7W_sQlwSrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(datos.Email.unique())"
      ],
      "metadata": {
        "id": "FUI39oJQUl9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Con el m茅todo <code>drop()</code> de <code>Pandas</code> se eliminan las columnas del <code>DataFrame</code> que ya no son 煤tiles. Descartamos <code>Avatar</code>, <code>Email</code> y <code>Address</code>."
      ],
      "metadata": {
        "id": "fPaUUhx5wuOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos = datos.drop([\"Avatar\",\"Email\",\"Address\"], axis=1)"
      ],
      "metadata": {
        "id": "N6NjvOk3UMjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Se renombran las columnas para asignarles nombres m谩s descriptivos y significativos. Es posible utilizar el m茅todo <code>rename()</code>."
      ],
      "metadata": {
        "id": "yNzjPBqoxTH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renombramos columnas:\n",
        "datos.rename(columns={\"Avg. Session Length\": \"Tiempo_sesi贸n\",\n",
        "                      \"Time on App\":\"Tiempo_app\",\n",
        "                      \"Time on Website\":\"Tiempo_web\",\n",
        "                      \"Length of Membership\":\"A帽os_miembro\",\n",
        "                      \"Yearly Amount Spent\":\"Gasto_anual\"},inplace=True)"
      ],
      "metadata": {
        "id": "vF4_tuZ723Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.head()"
      ],
      "metadata": {
        "id": "DaMepz7R23MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **An谩lisis exploratorio de datos (Estad铆stica Descriptiva)**"
      ],
      "metadata": {
        "id": "tK5HbyQ2cgAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Primero exploremos estos datos, antes de realizar la regresi贸n lineal para tomar una decisi贸n.\n",
        "<br>\n",
        "<br>\n",
        "Solo utilizaremos datos num茅ricos."
      ],
      "metadata": {
        "id": "ensOyk8rcqWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "_S2lYTjOntyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.describe().T.round(3)"
      ],
      "metadata": {
        "id": "yZSBzar_b8Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Distribuci贸n de los datos de la variable respuesta (`Gasto_anual`)**"
      ],
      "metadata": {
        "id": "XLPJ2jCJaakB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta l铆nea, se importa la funci贸n norm de la biblioteca scipy.stats. La funci贸n **norm** representa una distribuci贸n normal."
      ],
      "metadata": {
        "id": "t2yoWeN4UmZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm"
      ],
      "metadata": {
        "id": "-6UzmZ8XeT2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribuci贸n te贸rica\n",
        "mu, sigma = norm.fit(datos.Gasto_anual)\n",
        "print(mu)\n",
        "print(sigma)"
      ],
      "metadata": {
        "id": "dkaxUZmTaZ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**mu**: Representa la media de la distribuci贸n normal ajustada a los datos.\n",
        "**sigma**: Representa la desviaci贸n est谩ndar de la distribuci贸n normal ajustada a los datos.\n",
        "La funci贸n **fit** toma los datos de la columna Gasto_anual de datos y ajusta una distribuci贸n normal a esos datos, devolviendo la media (**mu**) y la desviaci贸n est谩ndar (**sigma**) de la distribuci贸n ajustada."
      ],
      "metadata": {
        "id": "sAJWnb25Uj44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(datos.Gasto_anual.min(),\n",
        "                datos.Gasto_anual.max(),\n",
        "                num = 100)\n",
        "y = norm.pdf(x, mu, sigma)"
      ],
      "metadata": {
        "id": "Qqv8GkErbeYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure([go.Scatter(x = x,\n",
        "                            y = y,\n",
        "                            line = {\"width\":3},\n",
        "                            name = \"Funci贸n Densidad de Probabilidad Te贸rica (Normal)\"),\n",
        "\n",
        "                 go.Histogram(x=datos.Gasto_anual,\n",
        "                              histnorm = \"probability density\",\n",
        "                              name = \"Distribuci贸n Real\")])\n",
        "\n",
        "fig.update_layout(template = \"simple_white\",\n",
        "                  title = \"Distribuci贸n del Gasto Anual\",\n",
        "                  )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "tEhgTcNEbdii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que el gasto anual (variable respuesta) est谩 normalmente distribuido."
      ],
      "metadata": {
        "id": "3aJk1dC9eb1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Matriz de correlaci贸n**"
      ],
      "metadata": {
        "id": "tFi3bA14Yh55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "La funci贸n <code>pearsonr</code> de la biblioteca <code>scipy.stats</code> en Python se utiliza para calcular el <b>coeficiente de correlaci贸n de Pearson</b> entre dos variables. El coeficiente de correlaci贸n de Pearson es una medida estad铆stica que eval煤a la fuerza y direcci贸n de la relaci贸n lineal entre dos variables continuas. El resultado de pearsonr es un par de valores: el <b>coeficiente de correlaci贸n</b> y el <b>p-valor</b> asociado.\n",
        "\n",
        "- El **coeficiente de correlaci贸n** de Pearson var铆a entre $-1$ y $1$. Un valor de $1$ indica una correlaci贸n positiva perfecta, lo que significa que las dos variables est谩n perfectamente relacionadas en una relaci贸n lineal positiva. Un valor de $-1$ indica una correlaci贸n negativa perfecta, lo que implica una relaci贸n lineal negativa perfecta entre las variables. Un valor cercano a $0$ indica una correlaci贸n d茅bil o inexistente entre las variables.\n",
        "\n",
        "- El **p-valor** asociado proporciona una medida de la significancia estad铆stica de la correlaci贸n calculada. Si el p-valor es menor que un umbral  predefinido (generalmente $0.05$), se considera que la correlaci贸n es estad铆sticamente significativa."
      ],
      "metadata": {
        "id": "xPdzxvdshven"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "8O13ArWleVk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlacion = pearsonr(x = datos.Tiempo_app, y =  datos.Gasto_anual)\n",
        "print(\"\")\n",
        "print(\"Coeficiente de correlaci贸n de Pearson: {}\".format(round(correlacion[0],4)))\n",
        "print(\"P-valor: {}\".format(correlacion[1]))"
      ],
      "metadata": {
        "id": "-P_XnJyIYl_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "El test de correlaci贸n muestran una <b>relaci贸n lineal positiva de intensidad media</b> (r = 0.5) y <b>estad铆sticamente significativa</b> (p-valor = 6.905842369973249e-33)."
      ],
      "metadata": {
        "id": "x1puvFf6zWZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "El m茅todo <code>corr()</code> en <code>Pandas</code> se utiliza para calcular la matriz de correlaci贸n entre las variables num茅ricas de un DataFrame. Esta matriz muestra las correlaciones entre pares de variables y es 煤til para analizar la relaci贸n lineal entre diferentes variables en un conjunto de datos."
      ],
      "metadata": {
        "id": "EYwq-x95z0uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = round(datos.corr(),3)\n",
        "corr_matrix"
      ],
      "metadata": {
        "id": "pfAPY0Z222_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "El <b>Mapa de calor</b> o <b>Heatmap</b> es una herramienta gr谩fica utilizada para visualizar y analizar la relaci贸n entre variables en un conjunto de datos.\n",
        "\n",
        "Tradicionalmente, la biblioteca [Seaborn](https://seaborn.pydata.org/generated/seaborn.heatmap.html) ha sido com煤nmente empleada para generar Mapas de calor.\n",
        "\n",
        "No obstante, en esta ocasi贸n hemos optado por utilizar la biblioteca [Plotly](https://plotly.com/python/imshow/) para llevar a cabo esta representaci贸n gr谩fica.\n",
        "\n"
      ],
      "metadata": {
        "id": "WhRFwOMV1LL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "px.imshow(corr_matrix,\n",
        "          title = \"Matriz de Correlacion\",\n",
        "          text_auto=True,\n",
        "          color_continuous_scale='fall',\n",
        "          labels={\"color\":\"Indice\"})"
      ],
      "metadata": {
        "id": "JnW8sexV229c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "A primera vista, se evidencia una relaci贸n fuerte entre la variable explicativa <code>A帽os_miembro</code> y la variable <code>Gasto_anual</code>. Asimismo, se puede apreciar una relaci贸n moderada entre la variable explicativa <code>Tiempo_app</code> y la variable <code>Gasto_anual</code>. La relaci贸n entre <code>Tiempo_web</code> y <code>Gasto_anual</code> es nula.\n",
        "<br>\n",
        "<br>\n",
        "No obstante, no se observa una correlaci贸n significativa entre las variables explicativas entre s铆. Esto indica que las variables explicativas son <b>independientes</b> entre s铆 y no hay una relaci贸n directa o sistem谩tica entre ellas en el conjunto de datos analizado. Cada una de ellas puede proporcionar informaci贸n 煤nica y no redundante para explicar la variable respuesta (<code>Gasto_anual</code>)"
      ],
      "metadata": {
        "id": "UnBJKqpI2xyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Scatterplot de cada variable explicativa**"
      ],
      "metadata": {
        "id": "wQ3vFD-8g8nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = datos[['Tiempo_sesi贸n', 'Tiempo_app','Tiempo_web','A帽os_miembro']]\n",
        "y = datos['Gasto_anual']"
      ],
      "metadata": {
        "id": "92Ie9k5V23Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "wJM6CR2sZKmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "spHyH3Ow224K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in X.columns:\n",
        "  fig = px.scatter(datos,\n",
        "             x = i,\n",
        "             y = y,\n",
        "             trendline=\"ols\",\n",
        "             trendline_color_override=\"darkorange\",\n",
        "             template = \"gridon\",\n",
        "             title = i)\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "zMhvp3Ut226y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **Estandarizaci贸n de variables num茅ricas</font>**"
      ],
      "metadata": {
        "id": "4yDhp-OBVTbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "<code>StandardScaler</code> es una clase de la biblioteca <code>scikit-learn</code> en Python que se utiliza para estandarizar variables num茅ricas en un conjunto de datos. La estandarizaci贸n es un paso com煤n en el preprocesamiento de datos antes de aplicar t茅cnicas de aprendizaje autom谩tico, ya que ayuda a que las variables tengan una escala com煤n y elimina cualquier sesgo relacionado con la escala de las variables explicativas.\n"
      ],
      "metadata": {
        "id": "ZkjMzfnL5xu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "nszBmH01ja_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "La clase <code>StandardScaler</code> implementa el m茅todo <code>fit_transform()</code> que se utiliza para ajustar y transformar los datos al mismo tiempo. Este m茅todo calcula la media y la desviaci贸n est谩ndar de cada variable del conjunto de datos y luego las utiliza para estandarizar cada registro. La estandarizaci贸n se realiza restando la media a cada registro y dividiendolo por la desviaci贸n est谩ndar, lo que resulta en variables con una media de cero y una desviaci贸n est谩ndar de uno."
      ],
      "metadata": {
        "id": "5i2NJIem6YVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled"
      ],
      "metadata": {
        "id": "DOuDUJy4kYIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Para transformar los datos estandarizados (<code>numpy array</code>) a un <code>DataFrame</code> es posible utilizar la biblioteca el m茅todo <code>DataFrame()</code> de <code>Pandas</code>. En resumen, este m茅todo permite crear un <code>DataFrame</code> a partir de la matriz de datos estandarizados."
      ],
      "metadata": {
        "id": "cUKdlcQm6xtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled = pd.DataFrame(X_scaled, columns = X.columns)\n",
        "X_scaled"
      ],
      "metadata": {
        "id": "SikoucfgkfX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **Divisi贸n del conjunto de datos</font>**"
      ],
      "metadata": {
        "id": "jBYjhfbwm2xB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Divisi贸n del conjunto de entrenamiento y prueba.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "maDN30FykfRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test  = train_test_split(X_scaled, y, random_state=123)"
      ],
      "metadata": {
        "id": "epi6n2xrm4LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "1PBVM27Ym__m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "WDbbtwNLnHO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "EoHbqI3-hkEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "pNhRSTZPhnHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **Ajuste del modelo con sklearn</font>**"
      ],
      "metadata": {
        "id": "JruD3jN4VKRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "La clase <code>LinearRegression</code> de <code>scikit-learn</code> proporciona una interfaz sencilla y eficiente para ajustar modelos de regresi贸n lineal y realizar predicciones. Es ampliamente utilizada en problemas de regresi贸n en los que se busca modelar y predecir una variable dependiente a partir de variables independientes mediante una relaci贸n lineal.\n",
        "<br>\n",
        "<br>\n",
        "En este caso, se intenta predecir el valor del <code>Gasto_anual</code> en funci贸n de las variables explicativas <code>Tiempo_sesi贸n</code>, <code>Tiempo_app</code>,\t<code>Tiempo_web</code> y <code>A帽os_miembro</code>.\n",
        "<br>\n",
        "<br>\n",
        "Problema de regresi贸n lineal m煤ltiple."
      ],
      "metadata": {
        "id": "SyX61-Hv8Jo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "Ke-ZsomOhqjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = LinearRegression().fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(f\"intercept = {model_1.intercept_}\")\n",
        "print(f\"coef = {model_1.coef_}\")"
      ],
      "metadata": {
        "id": "aK1epMTIksxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimimos el intercepto del modelo, que es el valor de y cuando todas las caracter铆sticas **(X)** son cero.\n",
        "\n",
        "Imprimimos los coeficientes asociados a cada caracter铆stica en **X**. Estos coeficientes representan la relaci贸n entre cada caracter铆stica y la variable de destino (**y**).\n",
        "\n",
        "En un modelo de regresi贸n lineal simple, esto ser铆a la pendiente de la l铆nea de regresi贸n. En modelos m谩s complejos con m煤ltiples caracter铆sticas, habr谩 un coeficiente para cada caracter铆stica."
      ],
      "metadata": {
        "id": "71nnnY1_exLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Interpretaci贸n**"
      ],
      "metadata": {
        "id": "qAkXmEWdh-_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$Gasto \\ anual = 499.1+25.1  Tiempo \\ sesi贸n + 38.6  Tiempo \\ app + 0.8  Tiempo \\ web + 61.6  A帽os\\ miembro$"
      ],
      "metadata": {
        "id": "kNGFUjLljucN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretaci贸n de los coeficientes:**\n",
        "\n",
        "Manteniendo las otras caracter铆sticas fijas,\n",
        "+ un incremento de 1 unidad en `Tiempo_sesi贸n` est谩 asociado con un incremento de 25.14 en `Gasto_anual`,\n",
        "+ un incremento de 1 unidad en `Tiempo_app` est谩 asociado con un incremento de 38.6 en `Gasto_anual`,\n",
        "+ un incremento de 1 unidad en `Tiempo_web` est谩 asociado con un incremento de 0.77 en `Gasto_anual`y\n",
        "+ un incremento de 1 unidad en `A帽os_miembro` est谩 asociado con un incremento de 61.59 en `Gasto_anual`."
      ],
      "metadata": {
        "id": "TSTW-8UPXlkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Predicci贸n y evaluaci贸n del modelo**"
      ],
      "metadata": {
        "id": "XeKRBLK7iEfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez ajustado el modelo, procedemos a realizar predicciones y evaluar su desempe帽o"
      ],
      "metadata": {
        "id": "1bDaAs0utX3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model_1.predict(X_test)\n",
        "prediction[:5]"
      ],
      "metadata": {
        "id": "xHkhkHYn221m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabla = pd.DataFrame({\"Prediccion\":prediction,\n",
        "                      \"Real\":y_test,\n",
        "                      \"Residuos\": (y_test-prediction),\n",
        "                      })\n",
        "tabla.head()"
      ],
      "metadata": {
        "id": "_BaEvdHppLrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "eyVq9x_8l9Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La funci贸n **score** en scikit-learn se utiliza para evaluar el rendimiento de un modelo en datos de prueba. En el contexto de la regresi贸n lineal, la funci贸n score devuelve el coeficiente de determinaci贸n (R^2).\n",
        "\n",
        "El coeficiente de determinaci贸n (R^2) es una medida estad铆stica que indica qu茅 tan bien el modelo se ajusta a los datos de prueba. Toma valores entre 0 y 1, donde 1 indica un ajuste perfecto y 0 indica que el modelo no explica nada de la variabilidad de los datos de prueba.\n",
        "\n",
        "En t茅rminos simples, un R^2 m谩s alto significa que el modelo es capaz de explicar una mayor proporci贸n de la variabilidad en los datos de prueba. Sin embargo, es importante tener en cuenta que un R^2 alto en los datos de prueba no garantiza un buen rendimiento en datos nuevos y no vistos. La evaluaci贸n del rendimiento del modelo debe hacerse con una combinaci贸n de m茅tricas y validaci贸n cruzada."
      ],
      "metadata": {
        "id": "9CBrwELGgOK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "SMSE = round(metrics.mean_squared_error(y_test, prediction,squared=False),2) #Error cuadr谩tico medio\n",
        "MAE = round(metrics.mean_absolute_error(y_test, prediction),2) #Error absoluto medio\n",
        "R2 = round(metrics.r2_score(y_test, prediction),4)\n",
        "print(\"\")\n",
        "print(\"SMSE: {}\".format(SMSE))\n",
        "print(\"MAE: {}\".format(MAE))\n",
        "print(\"R2: {}\".format(R2))"
      ],
      "metadata": {
        "id": "O_BvxWCOo_MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este c贸digo est谩 calculando diversas m茅tricas de evaluaci贸n del rendimiento de un modelo de regresi贸n.\n",
        "\n",
        "- **`SMSE` (Error cuadr谩tico medio):** Esta m茅trica mide la ra铆z cuadrada del error cuadr谩tico medio entre las predicciones del modelo y los valores reales del conjunto de prueba. Es una medida de cu谩nto se espera que var铆en las predicciones del modelo con respecto a los valores reales. Un SMSE m谩s bajo indica un mejor rendimiento del modelo.\n",
        "\n",
        "- **`MAE` (Error absoluto medio):** Esta m茅trica mide el promedio de las diferencias absolutas entre las predicciones del modelo y los valores reales en el conjunto de prueba. Es menos sensible a los valores at铆picos que el error cuadr谩tico medio. Un MAE m谩s bajo indica un mejor rendimiento del modelo.\n",
        "\n",
        "- **`R2` (Coeficiente de determinaci贸n):** Esta m茅trica, ya mencionada en una respuesta anterior, indica la proporci贸n de la varianza en la variable dependiente que es predecible a partir de las variables independientes. Toma valores entre 0 y 1, donde 1 indica un ajuste perfecto. Un R2 m谩s alto indica un mejor rendimiento del modelo.\n"
      ],
      "metadata": {
        "id": "qzrvqrxxhJ-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creaci贸n del Pipeline**"
      ],
      "metadata": {
        "id": "w_JpVwe4hgNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline"
      ],
      "metadata": {
        "id": "7sbMne1XaKgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(StandardScaler(), LinearRegression())\n",
        "model"
      ],
      "metadata": {
        "id": "hVg67557aKdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un pipeline es una forma de simplificar el flujo de trabajo en aprendizaje autom谩tico al combinar varias operaciones en un solo objeto. En este caso, el pipeline consta de dos pasos: **StandardScaler()** y **LinearRegression()**.\n",
        "\n",
        "El pipeline encapsula estos dos pasos en un solo objeto llamado **model**.\n",
        "\n",
        "Ahora, puedes entrenar y utilizar este modelo de manera m谩s sencilla, ya que el pipeline se encarga autom谩ticamente de aplicar la estandarizaci贸n antes de ajustar el modelo de regresi贸n lineal."
      ],
      "metadata": {
        "id": "hktUzQoUkRmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate"
      ],
      "metadata": {
        "id": "Ji6R36ZdaKbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = cross_validate(model, X, y, cv=5)\n",
        "cv_results"
      ],
      "metadata": {
        "id": "XIkr5UIoaKYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **La necesidad de validaci贸n cruzada</font>**"
      ],
      "metadata": {
        "id": "sK-KzRx-amZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "En el ejemplo anterior, se dividieron los datos originales en un conjunto de datos de entrenamiento y un conjunto de datos de prueba. La puntuaci贸n de la generalizaci贸n del modelo entonces, depender谩 en general de la forma en que se hace esa divisi贸n.\n",
        "<br><br>\n",
        "Una desventaja de hacer una sola divisi贸n, es que no da informaci贸n sobre esta variabilidad. Otro inconveniente, en un entorno donde la cantidad de datos es peque帽a, es que los datos disponibles para el entrenamiento y los datos disponibles para la prueba ser谩n a煤n m谩s peque帽a despu茅s de esa divisi贸n.\n",
        "<br><br>\n",
        "Entonces, podemos utilizar la validaci贸n cruzada.\n",
        "<br><br>\n",
        "La validaci贸n cruzada consiste en repetir el procedimiento de manera que el conjunto de datos de entrenamiento y el conjunto de datos de prueba sean diferentes en cada repetici贸n. Las m茅tricas de rendimiento de la generalizaci贸n del modelo se recopilan para cada repetici贸n. Como resultado, se puede evaluar la variabilidad del rendimiento del modelo.\n",
        "<br><br>\n",
        "\n",
        "Por ahora, vamos a usar la estrategia <code>K-fold</code> que implica que todo el conjunto de datos se divide en $K$ particiones. El procedimiento de ajuste <code>fit</code> y la evaluaci贸n <code>score</code> se repite $K$ veces donde en cada iteraci贸n $K - 1$ las particiones se usan para ajustar el modelo.\n",
        "<br><br>\n",
        "La siguiente figura ilustra esta estrategia <code>K-fold</code>.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "aJt7oIwMamTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/cristiandarioortegayubro/BDS/blob/main/images/k-fold-001.png?raw=true\" width=\"600\">\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "eJmNj-Fbde5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Esta figura muestra el caso particular de la estrategia de validaci贸n cruzada <code>K-fold</code>\n",
        "<br><br>\n",
        "Para cada divisi贸n de validaci贸n cruzada, el procedimiento entrena un clon del modelo en todos los puntos rojos y evalua la puntuaci贸n del modelo en los azules. Como se mencion贸 anteriormente, hay una variedad de diferentes validaciones cruzadas. Por lo tanto, la validaci贸n cruzada es computacionalmente intensiva porque requiere entrenar varios modelos, en vez de entrenar solo uno.\n",
        "<br><br>\n",
        "En <code>scikit-learn</code>, la funci贸n <code>cross_validate</code> permite realizar la validaci贸n cruzada y necesita pasar el modelo, los datos y la variable objetivo. El par谩metro <code>cv</code> define la estrategia de divisi贸n, es decir, en cuanto se divide...\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "CC-OGxFPamK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cv_results[\"test_score\"]\n",
        "print(\"\")\n",
        "print(\"El R2 mediante cross-validation es: \"\n",
        "      f\"{scores.mean():.3f} 卤 {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "d_2N_dHJaKVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*El modelo con todas las variables num茅ricas como predictores tiene un $^2$  muy alto (0.984), es capaz de explicar el 98.4% de la variabilidad observada en el* `Gasto_anual`."
      ],
      "metadata": {
        "id": "Lw5l78KJfVLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Conclusiones</font>**"
      ],
      "metadata": {
        "id": "AeFSFlMVY2kF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "A trav茅s de este ejercicio nosotros:<br>\n",
        "\n",
        "*  Estudiamos la correlaci贸n lineal entre variables.\n",
        "\n",
        "*  Procedimos a estandarizar las variables explicativas num茅ricas con el fin de homogeneizar su escala.\n",
        "\n",
        "*  Utilizamos la biblioteca <code>scikit-learn</code> para entrenar un modelo de regresi贸n lineal m煤ltiple.\n",
        "<br>\n",
        "*  Realizamos la predicci贸n y evaluaci贸n, usando diferentes m茅tricas, con un conjunto de prueba.\n",
        "<br>\n",
        "*  Implementamos un Pipeline y aplicamos la validaci贸n cruzada.\n",
        "<br>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hMlr5a9OY9xY"
      }
    }
  ]
}