{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cerino-rigo/EC3002C.602-2023/blob/main/manejo_datos_faltantes_categoricos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##El set de datos\n",
        "\n",
        "Usaremos un set de datos que contiene la información del sexo, el peso (en Kg) y la altura de un grupo de 600 personas:"
      ],
      "metadata": {
        "id": "QNz3DxNUnI8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nN0eHbZr5D_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CDxmYKj78MOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDCQBl4hSXtd"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "datos = pd.read_csv(\"/content/drive/MyDrive/Machine Learning/dataset_datos_faltantes_categoricos.csv\")\n",
        "datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribución de estos datos para el peso\n",
        "sns.histplot(data=datos, x='peso (kg)', hue='sexo');"
      ],
      "metadata": {
        "id": "jBWAnr2NnyZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para la altura\n",
        "sns.histplot(data=datos, x='altura (cm)', hue='sexo');"
      ],
      "metadata": {
        "id": "RIEDR9aroQH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos verificar si hay datos faltantes de varias formas.\n",
        "\n",
        "La primera es con el método `info()`:"
      ],
      "metadata": {
        "id": "twwS2IQnobzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "Ay8-9j9kSltQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que:\n",
        "\n",
        "- En total debería haber 600 datos\n",
        "- La columna `sexo` es categórica (`masculino` o `femenino`) y contiene 570 registros. Es decir, **faltan 30 registros**.\n",
        "- Las columnas `peso (kg)` y `altura (cm)` son numéricas y están completas\n",
        "\n",
        "Otra forma de ver la cantidad de datos faltantes es usando `isna()` y `sum()`:"
      ],
      "metadata": {
        "id": "wqq-oTTVou5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar la cantidad de datos faltantes (marcados como NaN) en cada columna\n",
        "datos.isna().sum()"
      ],
      "metadata": {
        "id": "yLek2QUzTW3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O también podemos usar `value_counts()` aplicado directamente sobre la columna `sexo`:"
      ],
      "metadata": {
        "id": "98ueoP4yp8va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos verificar que la suma no es igual a 600\n",
        "datos['sexo'].value_counts()"
      ],
      "metadata": {
        "id": "HxJ5x2hAp0ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formas de manejar datos faltantes para variables categóricas\n",
        "\n",
        "Cuando la variable \"problemática\" es categórica (como el caso de la columna `sexo`) podemos usar alguno de estos enfoques:\n",
        "\n",
        "1. Eliminar las filas con los registros faltantes\n",
        "2. Eliminar la columna \"problemática\"\n",
        "3. Imputar con la categoría más frecuente\n",
        "4. Imputar usando *Machine Learning* (**recomendado**)\n",
        "\n",
        "Veamos cada una de estas técnicas junto con sus ventajas y desventajas:"
      ],
      "metadata": {
        "id": "jDeiWlaUqJ4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###    Eliminar filas con los registros faltantes\n",
        "\n",
        "Consiste simplemente en quitar la fila completa para cada registro faltante.\n",
        "\n",
        "- Ventaja: ¡es el método más simple!\n",
        "- Desventajas:\n",
        "  - Si el dataset es \"pequeño\" la eliminación puede reducir significativamente su tamaño\n",
        "  - Lo anterior puede dificultar tareas posteriores como, el uso de modelos de *Machine Learning* para generar predicciones\n",
        "\n",
        "En el caso que nos interesa esta eliminación implica que por cada fila donde falta el dato del `sexo` también eliminaremos la información correspondiente a las columnas `peso (kg)` y `altura (cm)`.\n",
        "\n",
        "La eliminación se puede hacer con el método `dropna()` de Pandas, que permite eliminar los registros que contienen datos *NaN*:"
      ],
      "metadata": {
        "id": "YkFL-80KqoPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filas = datos.dropna(axis=0) # Axis = 0: eliminar filas\n",
        "df_filas.info()"
      ],
      "metadata": {
        "id": "--9iD4m9T2F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya no tenemos datos faltantes pero hemos pasado de 600 a 570 registros en total."
      ],
      "metadata": {
        "id": "2CzHuOx6rn2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eliminar columnas con los registros faltantes\n",
        "\n",
        "Consiste simplemente en quitar la columna \"problemática\":\n",
        "\n",
        "- Ventaja: ¡es el método más simple!\n",
        "- Desventajas:\n",
        "  - La eliminación de la columna \"problema\" puede dificultar tareas posteriores\n",
        "  - ¿Vale la pena eliminar toda una columna cuando tan sólo faltan unos cuantos datos?\n",
        "\n",
        "De nuevo, podemos usar el método `dropna()`:"
      ],
      "metadata": {
        "id": "bysVdN5sr0NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cols = datos.dropna(axis=1) # Axis = 1: eliminar columna(s)\n",
        "df_cols.info()"
      ],
      "metadata": {
        "id": "DaTYgnE_T3ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos preservado los 600 registros pero hemos eliminado una columna completa"
      ],
      "metadata": {
        "id": "2qiSag1TsR7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imputar con la categoría más frecuente\n",
        "\n",
        "Consiste en encontrar, en la columna \"problema\", la categoría (o nivel) que ocurre con mayor frecuencia y usarla para completar los datos faltantes.\n",
        "\n",
        "Por ejemplo, veamos la categoría más común en la columna `sexo`:"
      ],
      "metadata": {
        "id": "yC9gktOMsaUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos['sexo'].value_counts()"
      ],
      "metadata": {
        "id": "K0oJu5G0UVbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La categoría más común es `masculino` (288 datos en total). Así que en esta técnica de imputación usaríamos esta categoría para completar los datos faltantes.\n",
        "\n",
        "- Ventaja: no se eliminan ni filas ni columnas.\n",
        "- Desventaja: esta imputación puede generar sesgos\n",
        "\n",
        "Para realizar esta imputación podemos usar el método `fillna()` de Pandas que nos permite \"rellenar\" los *NaN* con el valor que especifiquemos:"
      ],
      "metadata": {
        "id": "A7t81RLjsvr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar una copia del DataFrame original\n",
        "df_frec = datos.copy()\n",
        "\n",
        "# Tomar la columna \"sexo\" y usar \"fillna\" para rellenar los valores\n",
        "# faltantes con la categoría \"masculino\"\n",
        "df_frec['sexo'] = df_frec['sexo'].fillna('masculino')\n",
        "\n",
        "# Verificar que ya no hay valores faltantes\n",
        "df_frec['sexo'].isna().sum()"
      ],
      "metadata": {
        "id": "LIRgqCG-UpdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataFrame.fillna(value=None, method=None)**\n",
        "\n",
        "Rellena los valores NA/NaN utilizando el método especificado."
      ],
      "metadata": {
        "id": "v03cE6yh9Y3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_frec"
      ],
      "metadata": {
        "id": "dUe_Cg9crcKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imputar usando *Machine Learning*\n",
        "\n",
        "Es el método **más robusto y más recomendado**.\n",
        "\n",
        "Consiste en construir un modelo de *Machine Learning* que tome las variables que están completas (por ejemplo `peso (kg)` y `altura (cm)`) y aprenda a predecir la variable incompleta (en este caso `sexo`):\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1FPhsrSLu5TlHSoDtNSRgjMpxc7rD4qsa)\n",
        "\n",
        "\n",
        "**Ventajas**\n",
        "- Se preserva la cantidad de datos\n",
        "- No se generan sesgos (siempre y cuando el modelo pueda ser construido correctamente)\n",
        "\n",
        "**Desventajas**\n",
        "- Se requieren suficientes datos para entrenar el modelo: no debe haber demasiados datos faltantes ni muy pocos datos de entrenamiento\n",
        "- Dependiendo del set de datos no siempre resulta sencillo construir un modelo que genere predicciones adecuadas\n",
        "\n",
        "**Procedimiento**\n",
        "1. Crear el set de entrenamiento: registros que contienen datos completos\n",
        "2. Crear el set de prueba: registros que contienen datos incompletos\n",
        "3. Escoger y entrenar el modelo de *Machine Learning* con el set de entrenamiento\n",
        "4. Predecir datos faltantes con el modelo entrenado y con el set de prueba\n",
        "5. Incorporar los datos predichos en el dataset\n",
        "\n",
        "Veamos en este ejemplo cómo implementar cada paso:"
      ],
      "metadata": {
        "id": "mRQGdN83tp0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Crear el set de entrenamiento\n",
        "\n",
        "# 1.1. Extraer las filas que contienen datos completos\n",
        "XY = datos.dropna().to_numpy()\n",
        "XY.shape"
      ],
      "metadata": {
        "id": "shbrp8mhVauy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XY"
      ],
      "metadata": {
        "id": "1omDuojA-4UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2. Set de entrenamiento\n",
        "# x_train: columnas 1 y 2 (\"peso (kg)\" y \"altura (cm)\")\n",
        "# y_train: columna 0 (\"sexo\")\n",
        "x_train = XY[:,1:3]\n",
        "y_train = XY[:,0]\n",
        "\n",
        "print(x_train)\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "KtrV0WLwvQwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Crear el set de prueba: filas con datos incompletos\n",
        "# y columnas \"peso (kg)\" y \"altura (cm)\"\n",
        "\n",
        "filas = datos[~datos['sexo'].notna()].index # Filas incompletas\n",
        "x_test = datos[['peso (kg)', 'altura (cm)']].iloc[filas].to_numpy()\n",
        "x_test"
      ],
      "metadata": {
        "id": "GiANK4RDvsQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El tercer paso es escoger y entrenar el modelo de Machine Learning con el set de entrenamiento.\n",
        "\n",
        "Para este ejemplo podemos usar un sencillo modelo de Regresión Logística.\n",
        "\n",
        "Pero antes de entrenarlo debemos pre-procesar los datos, pues las categorías a predecir (`masculino`, `femenino`) no pueden estar en formato de texto sino que deben estar en formato numérico (0 ó 1).\n",
        "\n",
        "Para hacer esta conversión podemos usar `LabelEncoder` de *Scikit Learn*:"
      ],
      "metadata": {
        "id": "R5x5-i45wJJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "le.classes_"
      ],
      "metadata": {
        "id": "zxho6woPV3Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y ahora convertimos \"y_train\" a representación numérica\n",
        "y_train = le.transform(y_train)\n",
        "y_train"
      ],
      "metadata": {
        "id": "GqjHz9coWRPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Después de construir el modelo, este generará predicciones\n",
        "# numéricas (0, 1). Para obtener la categoría correspondiente\n",
        "# usamos \"inverse_transform\". Por ejemplo:\n",
        "le.inverse_transform([0,1,1,0])"
      ],
      "metadata": {
        "id": "jVwvXs88X6av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con los datos pre-procesados podemos construir y entrenar el modelo usando el módulo `LogisticRegression` de *Scikit Learn*:"
      ],
      "metadata": {
        "id": "STR7F6WjxEg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar el módulo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Crear instancia del modelo\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Entrenarlo con \"fit\" y con los datos de entrenamiento\n",
        "lr.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "elXYA3qlapo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Y con pocas líneas de código ya tenemos entrenado este modelo!\n",
        "\n",
        "Veamos un ejemplo de predicción para entender cómo usarlo:"
      ],
      "metadata": {
        "id": "8nTjgO4LxZrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entrada = [[69.,140.]]     # Supondremos un peso de 69 Kg y una altura de 120 cm\n",
        "pred = lr.predict(entrada) # Generamos la predicción con predict\n",
        "cat = le.inverse_transform(pred) # Y hacemos la transformación inversa\n",
        "\n",
        "print(pred)\n",
        "print(cat)"
      ],
      "metadata": {
        "id": "xBMtxF4Lb7xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora sólo debemos hacer lo mismo pero con el set de prueba (`x_test`) que, recordemos, es el que contiene los datos de peso y altura para las filas para las cuales desconocemos el sexo:"
      ],
      "metadata": {
        "id": "_Hc3qXscxw2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones sobre el set de prueba\n",
        "preds = lr.predict(x_test)\n",
        "print(preds)\n",
        "\n",
        "# Transformaciones inversas\n",
        "cats = le.inverse_transform(preds)\n",
        "print(cats)"
      ],
      "metadata": {
        "id": "if_RIQuAcPp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo único que queda es tomar las predicciones que se encuentran en la lista `cats` y realizar la imputación:"
      ],
      "metadata": {
        "id": "_qtc1NTLyH2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ubicar las categorías predichas en las filas correspondientes\n",
        "# de la columna \"sexo\" en el dataframe resultante\n",
        "df_ml = datos.copy()\n",
        "df_ml.iloc[filas,0]= cats # \"sexo\" es la columna 0\n",
        "df_ml"
      ],
      "metadata": {
        "id": "fi3z61QZcdas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y verifiquemos que no hay datos faltantes\n",
        "df_ml['sexo'].isna().sum()"
      ],
      "metadata": {
        "id": "m8bzW4Aichua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "32AEnhIuvk_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}