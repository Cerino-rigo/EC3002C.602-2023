{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cerino-rigo/EC3002C.602-2023/blob/main/RegresionLinealMultiple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2SmePwcn289"
      },
      "source": [
        " # **Modelos supervisados: Regresión Lineal Multiple con `sklearn`**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tTVRht_XPly1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT2-msbVrSQk"
      },
      "source": [
        "## **Bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRdT1kd7rJ8o"
      },
      "source": [
        "# Operaciones matemáticas y estadísticas\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuHEoL90rnf2"
      },
      "source": [
        "# Visualización\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj64cpBhsW4Q"
      },
      "source": [
        "## **Conjunto de Datos**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"/content/drive/MyDrive/Machine Learning/Ecommerce_Customers.csv\""
      ],
      "metadata": {
        "id": "tIUUi5_ULJFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arsPyTGL1Ydp"
      },
      "source": [
        "datos = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OorC6dqD1apN"
      },
      "source": [
        "datos.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Es una empresa de comercio electrónico con sede en la ciudad de Nueva York que vende ropa en línea, pero también tienen sesiones de asesoramiento sobre estilo y ropa en la tienda. Los clientes , tienen sesiones/reuniones con un estilista personal, luego pueden ordenar a través de una aplicación móvil o sitio web la ropa que desean.\n",
        "<br>\n",
        "<br>\n",
        "Intentan identificar si debe enfocarse en mejorar su experiencia de aplicación movil o en su página web.\n",
        "<br>\n",
        "<br>\n",
        "Este es un conjunto de datos de los clientes de la empresa. El cual tiene información del cliente, como correo electrónico, dirección postal y su color de avatar. También tiene columnas de valores numéricos:\n",
        "\n",
        "* **Avg. Session Length**: duración promedio de sesiones de asesoramiento de estilo en la tienda.\n",
        "\n",
        "* **Time on App**: tiempo promedio de permanencia en la aplicación en minutos.\n",
        "\n",
        "* **Time on Website**: tiempo promedio de permanencia en el sitio web en minutos.\n",
        "\n",
        "* **Length of Membership**: cuántos años ha sido miembro el cliente.\n",
        "\n",
        "* **Yearly Amount Spent**: monto anual gastado en la plataforma.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_uKB9hczk38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "0RsmeDhgmnrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "En la biblioteca <code>Pandas</code>, el método <code>unique()</code> se utiliza para obtener los valores únicos presentes en una serie o columna de un DataFrame. El objetivo es revisar que no hayan clientes repetidos.  "
      ],
      "metadata": {
        "id": "lh7W_sQlwSrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(datos.Email.unique())"
      ],
      "metadata": {
        "id": "FUI39oJQUl9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Con el método <code>drop()</code> de <code>Pandas</code> se eliminan las columnas del <code>DataFrame</code> que ya no son útiles. Descartamos <code>Avatar</code>, <code>Email</code> y <code>Address</code>."
      ],
      "metadata": {
        "id": "fPaUUhx5wuOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos = datos.drop([\"Avatar\",\"Email\",\"Address\"], axis=1)"
      ],
      "metadata": {
        "id": "N6NjvOk3UMjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Se renombran las columnas para asignarles nombres más descriptivos y significativos. Es posible utilizar el método <code>rename()</code>."
      ],
      "metadata": {
        "id": "yNzjPBqoxTH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renombramos columnas:\n",
        "datos.rename(columns={\"Avg. Session Length\": \"Tiempo_sesión\",\n",
        "                      \"Time on App\":\"Tiempo_app\",\n",
        "                      \"Time on Website\":\"Tiempo_web\",\n",
        "                      \"Length of Membership\":\"Años_miembro\",\n",
        "                      \"Yearly Amount Spent\":\"Gasto_anual\"},inplace=True)"
      ],
      "metadata": {
        "id": "vF4_tuZ723Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.head()"
      ],
      "metadata": {
        "id": "DaMepz7R23MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Análisis exploratorio de datos (Estadística Descriptiva)**"
      ],
      "metadata": {
        "id": "tK5HbyQ2cgAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Primero exploremos estos datos, antes de realizar la regresión lineal para tomar una decisión.\n",
        "<br>\n",
        "<br>\n",
        "Solo utilizaremos datos numéricos."
      ],
      "metadata": {
        "id": "ensOyk8rcqWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "_S2lYTjOntyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.describe().T.round(3)"
      ],
      "metadata": {
        "id": "yZSBzar_b8Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Distribución de los datos de la variable respuesta (`Gasto_anual`)**"
      ],
      "metadata": {
        "id": "XLPJ2jCJaakB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta línea, se importa la función norm de la biblioteca scipy.stats. La función **norm** representa una distribución normal."
      ],
      "metadata": {
        "id": "t2yoWeN4UmZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm"
      ],
      "metadata": {
        "id": "-6UzmZ8XeT2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribución teórica\n",
        "mu, sigma = norm.fit(datos.Gasto_anual)\n",
        "print(mu)\n",
        "print(sigma)"
      ],
      "metadata": {
        "id": "dkaxUZmTaZ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**mu**: Representa la media de la distribución normal ajustada a los datos.\n",
        "**sigma**: Representa la desviación estándar de la distribución normal ajustada a los datos.\n",
        "La función **fit** toma los datos de la columna Gasto_anual de datos y ajusta una distribución normal a esos datos, devolviendo la media (**mu**) y la desviación estándar (**sigma**) de la distribución ajustada."
      ],
      "metadata": {
        "id": "sAJWnb25Uj44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(datos.Gasto_anual.min(),\n",
        "                datos.Gasto_anual.max(),\n",
        "                num = 100)\n",
        "y = norm.pdf(x, mu, sigma)"
      ],
      "metadata": {
        "id": "Qqv8GkErbeYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure([go.Scatter(x = x,\n",
        "                            y = y,\n",
        "                            line = {\"width\":3},\n",
        "                            name = \"Función Densidad de Probabilidad Teórica (Normal)\"),\n",
        "\n",
        "                 go.Histogram(x=datos.Gasto_anual,\n",
        "                              histnorm = \"probability density\",\n",
        "                              name = \"Distribución Real\")])\n",
        "\n",
        "fig.update_layout(template = \"simple_white\",\n",
        "                  title = \"Distribución del Gasto Anual\",\n",
        "                  )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "tEhgTcNEbdii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que el gasto anual (variable respuesta) está normalmente distribuido."
      ],
      "metadata": {
        "id": "3aJk1dC9eb1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Matriz de correlación**"
      ],
      "metadata": {
        "id": "tFi3bA14Yh55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "La función <code>pearsonr</code> de la biblioteca <code>scipy.stats</code> en Python se utiliza para calcular el <b>coeficiente de correlación de Pearson</b> entre dos variables. El coeficiente de correlación de Pearson es una medida estadística que evalúa la fuerza y dirección de la relación lineal entre dos variables continuas. El resultado de pearsonr es un par de valores: el <b>coeficiente de correlación</b> y el <b>p-valor</b> asociado.\n",
        "\n",
        "- El **coeficiente de correlación** de Pearson varía entre $-1$ y $1$. Un valor de $1$ indica una correlación positiva perfecta, lo que significa que las dos variables están perfectamente relacionadas en una relación lineal positiva. Un valor de $-1$ indica una correlación negativa perfecta, lo que implica una relación lineal negativa perfecta entre las variables. Un valor cercano a $0$ indica una correlación débil o inexistente entre las variables.\n",
        "\n",
        "- El **p-valor** asociado proporciona una medida de la significancia estadística de la correlación calculada. Si el p-valor es menor que un umbral  predefinido (generalmente $0.05$), se considera que la correlación es estadísticamente significativa."
      ],
      "metadata": {
        "id": "xPdzxvdshven"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "8O13ArWleVk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlacion = pearsonr(x = datos.Tiempo_app, y =  datos.Gasto_anual)\n",
        "print(\"\")\n",
        "print(\"Coeficiente de correlación de Pearson: {}\".format(round(correlacion[0],4)))\n",
        "print(\"P-valor: {}\".format(correlacion[1]))"
      ],
      "metadata": {
        "id": "-P_XnJyIYl_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "El test de correlación muestran una <b>relación lineal positiva de intensidad media</b> (r = 0.5) y <b>estadísticamente significativa</b> (p-valor = 6.905842369973249e-33)."
      ],
      "metadata": {
        "id": "x1puvFf6zWZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "El método <code>corr()</code> en <code>Pandas</code> se utiliza para calcular la matriz de correlación entre las variables numéricas de un DataFrame. Esta matriz muestra las correlaciones entre pares de variables y es útil para analizar la relación lineal entre diferentes variables en un conjunto de datos."
      ],
      "metadata": {
        "id": "EYwq-x95z0uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = round(datos.corr(),3)\n",
        "corr_matrix"
      ],
      "metadata": {
        "id": "pfAPY0Z222_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "El <b>Mapa de calor</b> o <b>Heatmap</b> es una herramienta gráfica utilizada para visualizar y analizar la relación entre variables en un conjunto de datos.\n",
        "\n",
        "Tradicionalmente, la biblioteca [Seaborn](https://seaborn.pydata.org/generated/seaborn.heatmap.html) ha sido comúnmente empleada para generar Mapas de calor.\n",
        "\n",
        "No obstante, en esta ocasión hemos optado por utilizar la biblioteca [Plotly](https://plotly.com/python/imshow/) para llevar a cabo esta representación gráfica.\n",
        "\n"
      ],
      "metadata": {
        "id": "WhRFwOMV1LL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "px.imshow(corr_matrix,\n",
        "          title = \"Matriz de Correlacion\",\n",
        "          text_auto=True,\n",
        "          color_continuous_scale='fall',\n",
        "          labels={\"color\":\"Indice\"})"
      ],
      "metadata": {
        "id": "JnW8sexV229c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "A primera vista, se evidencia una relación fuerte entre la variable explicativa <code>Años_miembro</code> y la variable <code>Gasto_anual</code>. Asimismo, se puede apreciar una relación moderada entre la variable explicativa <code>Tiempo_app</code> y la variable <code>Gasto_anual</code>. La relación entre <code>Tiempo_web</code> y <code>Gasto_anual</code> es nula.\n",
        "<br>\n",
        "<br>\n",
        "No obstante, no se observa una correlación significativa entre las variables explicativas entre sí. Esto indica que las variables explicativas son <b>independientes</b> entre sí y no hay una relación directa o sistemática entre ellas en el conjunto de datos analizado. Cada una de ellas puede proporcionar información única y no redundante para explicar la variable respuesta (<code>Gasto_anual</code>)"
      ],
      "metadata": {
        "id": "UnBJKqpI2xyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Scatterplot de cada variable explicativa**"
      ],
      "metadata": {
        "id": "wQ3vFD-8g8nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = datos[['Tiempo_sesión', 'Tiempo_app','Tiempo_web','Años_miembro']]\n",
        "y = datos['Gasto_anual']"
      ],
      "metadata": {
        "id": "92Ie9k5V23Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "wJM6CR2sZKmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "spHyH3Ow224K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in X.columns:\n",
        "  fig = px.scatter(datos,\n",
        "             x = i,\n",
        "             y = y,\n",
        "             trendline=\"ols\",\n",
        "             trendline_color_override=\"darkorange\",\n",
        "             template = \"gridon\",\n",
        "             title = i)\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "zMhvp3Ut226y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **Estandarización de variables numéricas</font>**"
      ],
      "metadata": {
        "id": "4yDhp-OBVTbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "<code>StandardScaler</code> es una clase de la biblioteca <code>scikit-learn</code> en Python que se utiliza para estandarizar variables numéricas en un conjunto de datos. La estandarización es un paso común en el preprocesamiento de datos antes de aplicar técnicas de aprendizaje automático, ya que ayuda a que las variables tengan una escala común y elimina cualquier sesgo relacionado con la escala de las variables explicativas.\n"
      ],
      "metadata": {
        "id": "ZkjMzfnL5xu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "nszBmH01ja_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "La clase <code>StandardScaler</code> implementa el método <code>fit_transform()</code> que se utiliza para ajustar y transformar los datos al mismo tiempo. Este método calcula la media y la desviación estándar de cada variable del conjunto de datos y luego las utiliza para estandarizar cada registro. La estandarización se realiza restando la media a cada registro y dividiendolo por la desviación estándar, lo que resulta en variables con una media de cero y una desviación estándar de uno."
      ],
      "metadata": {
        "id": "5i2NJIem6YVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled"
      ],
      "metadata": {
        "id": "DOuDUJy4kYIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Para transformar los datos estandarizados (<code>numpy array</code>) a un <code>DataFrame</code> es posible utilizar la biblioteca el método <code>DataFrame()</code> de <code>Pandas</code>. En resumen, este método permite crear un <code>DataFrame</code> a partir de la matriz de datos estandarizados."
      ],
      "metadata": {
        "id": "cUKdlcQm6xtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled = pd.DataFrame(X_scaled, columns = X.columns)\n",
        "X_scaled"
      ],
      "metadata": {
        "id": "SikoucfgkfX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **División del conjunto de datos</font>**"
      ],
      "metadata": {
        "id": "jBYjhfbwm2xB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "División del conjunto de entrenamiento y prueba.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "maDN30FykfRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test  = train_test_split(X_scaled, y, random_state=123)"
      ],
      "metadata": {
        "id": "epi6n2xrm4LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "1PBVM27Ym__m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "WDbbtwNLnHO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "EoHbqI3-hkEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "pNhRSTZPhnHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **Ajuste del modelo con sklearn</font>**"
      ],
      "metadata": {
        "id": "JruD3jN4VKRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "La clase <code>LinearRegression</code> de <code>scikit-learn</code> proporciona una interfaz sencilla y eficiente para ajustar modelos de regresión lineal y realizar predicciones. Es ampliamente utilizada en problemas de regresión en los que se busca modelar y predecir una variable dependiente a partir de variables independientes mediante una relación lineal.\n",
        "<br>\n",
        "<br>\n",
        "En este caso, se intenta predecir el valor del <code>Gasto_anual</code> en función de las variables explicativas <code>Tiempo_sesión</code>, <code>Tiempo_app</code>,\t<code>Tiempo_web</code> y <code>Años_miembro</code>.\n",
        "<br>\n",
        "<br>\n",
        "Problema de regresión lineal múltiple."
      ],
      "metadata": {
        "id": "SyX61-Hv8Jo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "Ke-ZsomOhqjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = LinearRegression().fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(f\"intercept = {model_1.intercept_}\")\n",
        "print(f\"coef = {model_1.coef_}\")"
      ],
      "metadata": {
        "id": "aK1epMTIksxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimimos el intercepto del modelo, que es el valor de y cuando todas las características **(X)** son cero.\n",
        "\n",
        "Imprimimos los coeficientes asociados a cada característica en **X**. Estos coeficientes representan la relación entre cada característica y la variable de destino (**y**).\n",
        "\n",
        "En un modelo de regresión lineal simple, esto sería la pendiente de la línea de regresión. En modelos más complejos con múltiples características, habrá un coeficiente para cada característica."
      ],
      "metadata": {
        "id": "71nnnY1_exLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Interpretación**"
      ],
      "metadata": {
        "id": "qAkXmEWdh-_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$Gasto \\ anual = 499.1+25.1 × Tiempo \\ sesión + 38.6 × Tiempo \\ app + 0.8 × Tiempo \\ web + 61.6 × Años\\ miembro$"
      ],
      "metadata": {
        "id": "kNGFUjLljucN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretación de los coeficientes:**\n",
        "\n",
        "Manteniendo las otras características fijas,\n",
        "+ un incremento de 1 unidad en `Tiempo_sesión` está asociado con un incremento de 25.14 en `Gasto_anual`,\n",
        "+ un incremento de 1 unidad en `Tiempo_app` está asociado con un incremento de 38.6 en `Gasto_anual`,\n",
        "+ un incremento de 1 unidad en `Tiempo_web` está asociado con un incremento de 0.77 en `Gasto_anual`y\n",
        "+ un incremento de 1 unidad en `Años_miembro` está asociado con un incremento de 61.59 en `Gasto_anual`."
      ],
      "metadata": {
        "id": "TSTW-8UPXlkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Predicción y evaluación del modelo**"
      ],
      "metadata": {
        "id": "XeKRBLK7iEfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez ajustado el modelo, procedemos a realizar predicciones y evaluar su desempeño"
      ],
      "metadata": {
        "id": "1bDaAs0utX3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model_1.predict(X_test)\n",
        "prediction[:5]"
      ],
      "metadata": {
        "id": "xHkhkHYn221m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabla = pd.DataFrame({\"Prediccion\":prediction,\n",
        "                      \"Real\":y_test,\n",
        "                      \"Residuos\": (y_test-prediction),\n",
        "                      })\n",
        "tabla.head()"
      ],
      "metadata": {
        "id": "_BaEvdHppLrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "eyVq9x_8l9Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función **score** en scikit-learn se utiliza para evaluar el rendimiento de un modelo en datos de prueba. En el contexto de la regresión lineal, la función score devuelve el coeficiente de determinación (R^2).\n",
        "\n",
        "El coeficiente de determinación (R^2) es una medida estadística que indica qué tan bien el modelo se ajusta a los datos de prueba. Toma valores entre 0 y 1, donde 1 indica un ajuste perfecto y 0 indica que el modelo no explica nada de la variabilidad de los datos de prueba.\n",
        "\n",
        "En términos simples, un R^2 más alto significa que el modelo es capaz de explicar una mayor proporción de la variabilidad en los datos de prueba. Sin embargo, es importante tener en cuenta que un R^2 alto en los datos de prueba no garantiza un buen rendimiento en datos nuevos y no vistos. La evaluación del rendimiento del modelo debe hacerse con una combinación de métricas y validación cruzada."
      ],
      "metadata": {
        "id": "9CBrwELGgOK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "SMSE = round(metrics.mean_squared_error(y_test, prediction,squared=False),2) #Error cuadrático medio\n",
        "MAE = round(metrics.mean_absolute_error(y_test, prediction),2) #Error absoluto medio\n",
        "R2 = round(metrics.r2_score(y_test, prediction),4)\n",
        "print(\"\")\n",
        "print(\"SMSE: {}\".format(SMSE))\n",
        "print(\"MAE: {}\".format(MAE))\n",
        "print(\"R2: {}\".format(R2))"
      ],
      "metadata": {
        "id": "O_BvxWCOo_MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código está calculando diversas métricas de evaluación del rendimiento de un modelo de regresión.\n",
        "\n",
        "- **`SMSE` (Error cuadrático medio):** Esta métrica mide la raíz cuadrada del error cuadrático medio entre las predicciones del modelo y los valores reales del conjunto de prueba. Es una medida de cuánto se espera que varíen las predicciones del modelo con respecto a los valores reales. Un SMSE más bajo indica un mejor rendimiento del modelo.\n",
        "\n",
        "- **`MAE` (Error absoluto medio):** Esta métrica mide el promedio de las diferencias absolutas entre las predicciones del modelo y los valores reales en el conjunto de prueba. Es menos sensible a los valores atípicos que el error cuadrático medio. Un MAE más bajo indica un mejor rendimiento del modelo.\n",
        "\n",
        "- **`R2` (Coeficiente de determinación):** Esta métrica, ya mencionada en una respuesta anterior, indica la proporción de la varianza en la variable dependiente que es predecible a partir de las variables independientes. Toma valores entre 0 y 1, donde 1 indica un ajuste perfecto. Un R2 más alto indica un mejor rendimiento del modelo.\n"
      ],
      "metadata": {
        "id": "qzrvqrxxhJ-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creación del Pipeline**"
      ],
      "metadata": {
        "id": "w_JpVwe4hgNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline"
      ],
      "metadata": {
        "id": "7sbMne1XaKgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(StandardScaler(), LinearRegression())\n",
        "model"
      ],
      "metadata": {
        "id": "hVg67557aKdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un pipeline es una forma de simplificar el flujo de trabajo en aprendizaje automático al combinar varias operaciones en un solo objeto. En este caso, el pipeline consta de dos pasos: **StandardScaler()** y **LinearRegression()**.\n",
        "\n",
        "El pipeline encapsula estos dos pasos en un solo objeto llamado **model**.\n",
        "\n",
        "Ahora, puedes entrenar y utilizar este modelo de manera más sencilla, ya que el pipeline se encarga automáticamente de aplicar la estandarización antes de ajustar el modelo de regresión lineal."
      ],
      "metadata": {
        "id": "hktUzQoUkRmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate"
      ],
      "metadata": {
        "id": "Ji6R36ZdaKbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = cross_validate(model, X, y, cv=5)\n",
        "cv_results"
      ],
      "metadata": {
        "id": "XIkr5UIoaKYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **La necesidad de validación cruzada</font>**"
      ],
      "metadata": {
        "id": "sK-KzRx-amZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "En el ejemplo anterior, se dividieron los datos originales en un conjunto de datos de entrenamiento y un conjunto de datos de prueba. La puntuación de la generalización del modelo entonces, dependerá en general de la forma en que se hace esa división.\n",
        "<br><br>\n",
        "Una desventaja de hacer una sola división, es que no da información sobre esta variabilidad. Otro inconveniente, en un entorno donde la cantidad de datos es pequeña, es que los datos disponibles para el entrenamiento y los datos disponibles para la prueba serán aún más pequeña después de esa división.\n",
        "<br><br>\n",
        "Entonces, podemos utilizar la validación cruzada.\n",
        "<br><br>\n",
        "La validación cruzada consiste en repetir el procedimiento de manera que el conjunto de datos de entrenamiento y el conjunto de datos de prueba sean diferentes en cada repetición. Las métricas de rendimiento de la generalización del modelo se recopilan para cada repetición. Como resultado, se puede evaluar la variabilidad del rendimiento del modelo.\n",
        "<br><br>\n",
        "\n",
        "Por ahora, vamos a usar la estrategia <code>K-fold</code> que implica que todo el conjunto de datos se divide en $K$ particiones. El procedimiento de ajuste <code>fit</code> y la evaluación <code>score</code> se repite $K$ veces donde en cada iteración $K - 1$ las particiones se usan para ajustar el modelo.\n",
        "<br><br>\n",
        "La siguiente figura ilustra esta estrategia <code>K-fold</code>.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "aJt7oIwMamTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/cristiandarioortegayubro/BDS/blob/main/images/k-fold-001.png?raw=true\" width=\"600\">\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "eJmNj-Fbde5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "Esta figura muestra el caso particular de la estrategia de validación cruzada <code>K-fold</code>\n",
        "<br><br>\n",
        "Para cada división de validación cruzada, el procedimiento entrena un clon del modelo en todos los puntos rojos y evalua la puntuación del modelo en los azules. Como se mencionó anteriormente, hay una variedad de diferentes validaciones cruzadas. Por lo tanto, la validación cruzada es computacionalmente intensiva porque requiere entrenar varios modelos, en vez de entrenar solo uno.\n",
        "<br><br>\n",
        "En <code>scikit-learn</code>, la función <code>cross_validate</code> permite realizar la validación cruzada y necesita pasar el modelo, los datos y la variable objetivo. El parámetro <code>cv</code> define la estrategia de división, es decir, en cuanto se divide...\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "CC-OGxFPamK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cv_results[\"test_score\"]\n",
        "print(\"\")\n",
        "print(\"El R2 mediante cross-validation es: \"\n",
        "      f\"{scores.mean():.3f} ± {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "d_2N_dHJaKVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*El modelo con todas las variables numéricas como predictores tiene un $𝑅^2$  muy alto (0.984), es capaz de explicar el 98.4% de la variabilidad observada en el* `Gasto_anual`."
      ],
      "metadata": {
        "id": "Lw5l78KJfVLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Conclusiones</font>**"
      ],
      "metadata": {
        "id": "AeFSFlMVY2kF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\">\n",
        "A través de este ejercicio nosotros:<br>\n",
        "\n",
        "*  Estudiamos la correlación lineal entre variables.\n",
        "\n",
        "*  Procedimos a estandarizar las variables explicativas numéricas con el fin de homogeneizar su escala.\n",
        "\n",
        "*  Utilizamos la biblioteca <code>scikit-learn</code> para entrenar un modelo de regresión lineal múltiple.\n",
        "<br>\n",
        "*  Realizamos la predicción y evaluación, usando diferentes métricas, con un conjunto de prueba.\n",
        "<br>\n",
        "*  Implementamos un Pipeline y aplicamos la validación cruzada.\n",
        "<br>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hMlr5a9OY9xY"
      }
    }
  ]
}